# Copyright 2025 Advanced Micro Devices, Inc.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

name: Release Generate IRPA for models

on:
  workflow_dispatch:
  schedule:
    # Runs on Sunday only
    - cron: "0 9 * * 7"

concurrency:
  # A PR number if a pull request and otherwise the commit hash. This cancels
  # queued and in-progress runs for the same PR (presubmit) or commit
  # (postsubmit). The workflow name is prepended to avoid conflicts between
  # different workflows.
  group: ${{ github.workflow }}-${{ github.event.number || github.sha }}
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  test_sdxl_flux_serving:
    if: ${{ github.repository_owner == 'nod-ai' || github.event_name != 'schedule' }}
    timeout-minutes: 240
    name: "Release: Generate IRPA for models"
    strategy:
      matrix:
        version: [3.11]
      fail-fast: false
    runs-on: linux-mi325-1gpu-ossci-nod-ai
    defaults:
      run:
        shell: bash
    env:
      VENV_DIR: ${{ github.workspace }}/.venv
      HF_HOME: "/shark-cache/data/huggingface"
      HF_TOKEN: ${{ secrets.HF_FLUX_TOKEN }}
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: ${{matrix.version}}
      - name: Create Python venv
        run: |
          python -m venv ${VENV_DIR}
          source ${VENV_DIR}/bin/activate

      - name: Install pip deps
        run: bash scripts/setenv.sh --nightly

      - name: Export 8B-FP16 instruct model
        run: |
          bash scripts/download_export_irpa.sh \
            --model Llama-3.1-8B-Instruct \
            --hf-token ${HF_TOKEN}
      - name: Export 70B-FP16 instruct model
        run: |
          bash scripts/download_export_irpa.sh \
            --model Llama-3.1-70B-Instruct \
            --hf-token ${HF_TOKEN}
      - name: Export Mistral-Nemo-Instruct-2407-FP8
        run: |
          bash scripts/download_export_irpa.sh \
            --model Mistral-Nemo-Instruct-2407-FP8 \
            --hf-token ${HF_TOKEN}

      - name: Cleanup download Directory
        run: |
          rm -rf Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct
          test ! -d Llama-3.1-8B-Instruct  && echo "Llama-3.1-8B-Instruct downaloaded artifacts removed"
          test ! -d Llama-3.1-70B-Instruct  && echo "Llama-3.1-70B-Instruct downaloaded artifacts removed"
          test ! -d Mistral-Nemo-Instruct-2407-FP8  && echo "Mistral-Nemo-Instruct-2407-FP8 downaloaded artifacts removed"
